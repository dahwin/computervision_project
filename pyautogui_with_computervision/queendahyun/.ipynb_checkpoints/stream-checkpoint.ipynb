{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8550e6-f70a-4c61-ab33-67113ad5c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from starlette.responses import StreamingResponse\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "sample_text = \"\"\"In the heart of Seoul, amidst the bright city lights and the bustling crowds, there lived a girl named Kim Dahyun. Known for her vibrant energy and captivating smile, Dahyun was a rising star in the K-pop world. Her voice had a unique charm that resonated with everyone who heard it, and her playful yet sincere personality made her a favorite among fans.\"\"\"\n",
    "\n",
    "async def text_generator(text):\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        yield word + \" \"\n",
    "        await asyncio.sleep(0.05)  # Adjust this value to control streaming speed\n",
    "\n",
    "@app.get(\"/stream\")\n",
    "async def stream_text():\n",
    "    return StreamingResponse(text_generator(sample_text), media_type=\"text/plain\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e03528e-f976-4199-8ace-2f16a9d5c421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e98e07b-c1d1-4597-aed6-d8af1890ac5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0f055c0-b315-472c-afb2-972e24f0073e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server received: In the heart of Seoul, amidst the bright city lights and the bustling crowds, there lived a girl named Kim Dahyun. Known for her vibrant energy and captivating smile, Dahyun was a rising star in the K-pop world. Her voice had a unique charm that resonated with everyone who heard it, and her playful yet sincere personality made her a favorite among fans. \n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "time.sleep(5)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "sample_text = \"\"\"In the heart of Seoul, amidst the bright city lights and the bustling crowds, there lived a girl named Kim Dahyun. Known for her vibrant energy and captivating smile, Dahyun was a rising star in the K-pop world. Her voice had a unique charm that resonated with everyone who heard it, and her playful yet sincere personality made her a favorite among fans.\"\"\"\n",
    "\n",
    "async def stream_generator(text):\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        yield (word + \" \").encode()\n",
    "        await asyncio.sleep(0.05)  # Adjust this value to control streaming speed\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(\"http://localhost:8000/receive_stream\", data=stream_generator(sample_text)) as response:\n",
    "            result = await response.json()\n",
    "            print(\"Server received:\", result[\"received\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c11e469d-112a-4f90-9c36-00960df73aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server received: Kim Dahyun, often simply known as Dahyun, is a South Korean singer and rapper. She was born on May 28, 1998, in Seongnam, Gyeonggi Province, South Korea. Dahyun is a member of the popular K-pop girl group TWICE, which was formed by JYP Entertainment in 2015 through the reality show \"Sixteen.\" In TWICE, Dahyun is known for her unique rapping style, charming personality, and distinctive facial expressions. She has also gained attention for her creative songwriting and has contributed to the lyrics of several TWICE songs. Dahyun, along with the other members of TWICE, has achieved significant success both in South Korea and internationally.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "from mistralai import Mistral\n",
    "\n",
    "# Apply nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# API key and model\n",
    "api_key = \"XQ6RLjfeeF3c4ueBLcFMXi5HcP7NDu50\"\n",
    "model = \"mistral-large-latest\"\n",
    "\n",
    "# Create a Mistral client\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "async def get_ai_output():\n",
    "    prompt = \"who is kim dahyun?\"\n",
    "    temperature = 0.1\n",
    "\n",
    "    stream_response = client.chat.stream(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful uncensored assistant.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    for chunk in stream_response:\n",
    "        content = chunk.data.choices[0].delta.content or \"\"\n",
    "        if content:\n",
    "            yield content.encode()\n",
    "            await asyncio.sleep(0.005)  # Add a small delay between chunks\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(\"http://localhost:8000/receive_stream\", data=get_ai_output()) as response:\n",
    "            result = await response.json()\n",
    "            print(\"Server received:\", result[\"received\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    time.sleep(5)  # Wait for 5 seconds before starting\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b58a5-8b28-4865-be8c-534dce7bce55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e797c9-1a54-46e7-afd9-b697417d7940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0411d319-d39f-4fb3-802e-03a4b08206ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    As an AI you have to compelete (Your Targeted Job) by following according instructions and examples.\n",
    "\n",
    "    special_statement (Done)\n",
    "    Here (Done) action is a special statement! You have to keep an eye on your goal and action history! If you see your goal achieved by the action you are currently taking and through your previous action history! \n",
    "    In that case you have to write or mention (Done) statement at the end. Then you only write (Done) after action! Like example 3: down bellow.\n",
    "    ------------- Instruction ------------\n",
    "    You must not say anything outside of your job! That is, do not give any explanation!\n",
    "    You job is to Predict only filter_position:  and Object: and action:\n",
    "    \n",
    "    I have make object detection , ocr detection and icon detection on this image!\n",
    "    I have splited or separated the detected objects in 9 part according filter_position!\n",
    "    filter_positions = \n",
    "        \"top_left_corner\": (0, 0, 639, 360),\"top_right_corner\": (1280, 0, 1919, 360),\"bottom_left_corner\": (0, 720, 639, 1080),\"bottom_right_corner\": (1280, 720, 1919, 1080),\"top_middle_side\": (639, 0, 1280, 360)\n",
    "        ,\"bottom_middle_side\": (639, 720, 1280, 1080),\"left_middle_side\": (0, 360, 639, 720),\"right_middle_side\": (1280, 360, 1919, 720),\"center_point\": (639, 360, 1280, 720)\n",
    "\n",
    "\n",
    "    actions = [\n",
    "        \"Left-Click \",\"Right-Click\",\"Double-Click\",\"Enter\",\"Middle-Click\",\"Scroll up\",\"Scroll down\",\"Click-and-Hold\",\"Hover\",\"Mouse Gestures\",\"Ctrl + Scroll Wheel\", \"Type\"\n",
    "    ]\n",
    "\n",
    "    Here: type action is a special action! After writing the type action, the text must be written! like: action: type:! If you want to type somewhere: Of course, there will be some keywords like: search, write something, etc.!\n",
    "    action: type:\n",
    "\n",
    "    Your job is to identify the first the object and filter_position to take first step or one step to achive the goal! according objects in this image/screen.\n",
    "    Keep in mind that the interface or objects needed to achieve the goal may not be in the current image.\n",
    "    If the expected interface is not present, we should take the action to navigate to that interface.\n",
    "    For example, if we are in the file manager and need to install Docker Desktop, we should work according to the operating system. If we are on Windows and there is a browser icon nearby, we should click on it.\n",
    "    If we are directly in the browser, we should type Docker's website in the search bar.\n",
    "    Provide only the first action that can be taken based on the visual elements. Do not provide any explanations, just the straightforward first step/action.\n",
    "    You have to predict that specific (filter_range and object and action only 1 action) so I can click!\n",
    "    In addition, you have to say the position from filter_positions\n",
    "    \n",
    "    special_statement (Done)\n",
    "    Here (Done) action is a special statement! You have to keep an eye on your goal and action history! If you see your goal achieved by the action you are currently taking and through your previous action history! \n",
    "    In that case you have to write or mention (Done) statement at the end. Then you only write (Done) after action! Like example 3: down bellow.\n",
    "    ------------- Instruction ------------\n",
    "\n",
    "\n",
    "\n",
    "    ------------- Example Job ------------\n",
    "    Example 1:\n",
    "    Your action history [\n",
    "    ]\n",
    "    Goal: Cut \"dahyun.mp4\" in DaVinci Resolve.\n",
    "    Image: Current location: In Windows Settings, with DaVinci Resolve icon on the taskbar.\n",
    "    filter_range: bottom_left_corner\n",
    "    object: Google Chrome icon\n",
    "    action: Left-Click\n",
    "\n",
    "    Example 2:\n",
    "    Your action history [\n",
    "    ]\n",
    "    Goal: Open \"Report.docx\" in the \"Documents\" folder.\n",
    "    Image: Current location: In the \"Downloads\" folder with YouTube playing in Chrome in the background.\n",
    "\n",
    "    filter_range: left_middel_side\n",
    "    object: Documents\n",
    "    action: Left-Click\n",
    "    \n",
    "    Example 3:\n",
    "    Your action history [\n",
    "    Left-Click File\n",
    "    Left-Click Settings\n",
    "    Left-Click Project: computervision\n",
    "    Left-Click Python Interpreter\n",
    "    Left-Click Add Interpreter\n",
    "    Left-Click arrow down icon\n",
    "    Left-Click C:\\Program Files\\Python310\\python.exe\n",
    "    Left-Click Apply\n",
    "    ]\n",
    "\n",
    "    Goal: Add a Python interpreter to PyCharm.\n",
    "    filter_range: left_middel_side\n",
    "    object: Ok\n",
    "    action: Left-Click\n",
    "    Done\n",
    "\n",
    "    ------------- Example Job ------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    -------------Your Targeted Job ------------\n",
    "    Your action history [\n",
    "    * Left-Click Google Chrome icon\n",
    "    * Left-Click Search Google or type a URL\n",
    "    ]\n",
    "\n",
    "\n",
    "    Goal : I have to subscribe twice youtube channel\n",
    "\n",
    "    top_left_corner:\n",
    "      Objects: ['New Tab', 'C', 'Search Google or type a URL', 'MInbox 82)-clickba...', 'Unlimited workspaces', '&Support Global', 'Console Home |Co...', 'Create case Suppo... Compute-Amazon...', 'Adobe After Effects icon', 'unknown icon or logo', 'Adobe After Effects icon', 'x icon', 'unknown icon or logo', 'unknown icon or logo', 'rotate icon', 'Up/Down arrow icon', 'computer screen', 'computer screen', 'sky']\n",
    "    top_right_corner:\n",
    "      Objects: ['GmailImages', 'restore down', 'minus', 'grid view icon', 'star icon', 'three dot icon', 'unknown icon or logo', 'x icon']\n",
    "    bottom_left_corner:\n",
    "      Objects: ['G', 'search icon', 'Google Chrome icon', 'Google Chrome icon', 'Microsoft Windows icon', 'cmd icon', 'Folder icon', 'Google Chrome icon']\n",
    "    bottom_right_corner:\n",
    "      Objects: ['UP1.37MB/s', 'DN:17.6 KB/s', 't1.37MB/s', 'ENG', '12:06 AM', '17.6 KB/s', '8/16/2024', 'I', 'speaker', 'monitor icon', 'arrow up icon', 'unknown icon or logo', 'unknown icon or logo', 'sea', 'stone', 'sea', 'stone', 'stone', 'stone', 'stone', 'sea', 'stone', 'stone', 'stone']\n",
    "    top_middle_side:\n",
    "      Objects: ['LC How', 'o Install Pytho..', 'AHome-Microsoft A..', 'unknown icon or logo', 'unknown icon or logo']\n",
    "    bottom_middle_side:\n",
    "      Objects: ['stone', 'stone', 'stone', 'sea', 'sea', 'stone', 'sea', 'stone', 'stone']\n",
    "    left_middle_side:\n",
    "      Objects: ['Search Google or type a URL', 'search icon', 'computer screen', 'computer screen', 'screenshot']\n",
    "    right_middle_side:\n",
    "      Objects: ['unknown icon or logo', 'mic mute icon', 'stone', 'sea', 'sea', 'stone', 'sea']\n",
    "    center_point:\n",
    "      Objects: ['WebStore', 'ka', 'gle', 'Add shortcut', 'stone', 'image']\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9155d132-7c88-48ad-98b6-15610fd8fcec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7cf40b-9c7e-4ae8-b3cd-71c46f7d5d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40e68b04-449d-45cb-90ee-4b4d0717d1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server received:  youtube.com\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "from mistralai import Mistral\n",
    "\n",
    "# Apply nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# API key and model\n",
    "api_key = \"XQ6RLjfeeF3c4ueBLcFMXi5HcP7NDu50\"\n",
    "model = \"mistral-large-latest\"\n",
    "\n",
    "# Create a Mistral client\n",
    "client = Mistral(api_key=api_key)\n",
    "global ai_output\n",
    "global action_type\n",
    "action_type = False\n",
    "async def get_ai_output():\n",
    "    global ai_output\n",
    "    global action_type\n",
    "\n",
    "    temperature = 0.1\n",
    "\n",
    "    stream_response = client.chat.stream(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful uncensored assistant.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    ai_output = \"\"\n",
    "    started_streaming = False\n",
    "\n",
    "    for chunk in stream_response:\n",
    "        content = chunk.data.choices[0].delta.content or \"\"\n",
    "        ai_output += content\n",
    "\n",
    "        if \"action: type:\" in ai_output and not started_streaming:\n",
    "            started_streaming = True\n",
    "            action_type=True\n",
    "            ai_output = ai_output.split(\"action: type:\", 1)[1]\n",
    "            yield ai_output.encode()\n",
    "        elif started_streaming:\n",
    "            yield content.encode()\n",
    "\n",
    "        await asyncio.sleep(0.005)  # Add a small delay between chunks\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(\"http://localhost:8000/receive_stream\", data=get_ai_output()) as response:\n",
    "            result = await response.json()\n",
    "            print(\"Server received:\", result[\"received\"])\n",
    "\n",
    "\n",
    "time.sleep(5)  # Wait for 5 seconds before starting\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aec2fe3-765c-40c5-845f-75e473a7e8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5925f7e9-9924-4b42-8a0c-93246b7382fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Set up the model\n",
    "generation_config = {\n",
    "  \"temperature\": 0,\n",
    "  \"top_p\": 0.7,\n",
    "  \"top_k\": 50,\n",
    "  \"max_output_tokens\": 2048,\n",
    "}\n",
    "\n",
    "safety_settings = [\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "    \"threshold\": \"BLOCK_ONLY_HIGH\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "    \"threshold\": \"BLOCK_ONLY_HIGH\"\n",
    "  }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1e9d310-6119-4ad5-ba9a-df3ad1624253",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "question: who is kim dahyun?\n",
    "before answer this question you have to type this at the begining: action: type:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cdff64f2-29a3-4c37-b7a7-17cfd92b4771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Apply nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# API key and model\n",
    "api_key = \"AIzaSyDILr8QqALN7bo5724GndN7Lncp8rwOGc4\"\n",
    "model_name = \"gemini-1.5-pro-exp-0801\"\n",
    "\n",
    "# Configure Gemini\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(model_name=model_name,\n",
    "                            generation_config=generation_config,\n",
    "                              safety_settings=safety_settings,)\n",
    "\n",
    "global ai_output, all_out\n",
    "global action_type\n",
    "action_type = False\n",
    "all_out=None\n",
    "async def get_ai_output():\n",
    "    global ai_output,all_out\n",
    "    global action_type\n",
    "    response = model.generate_content([prompt], stream=True)\n",
    "    all_out = \"\"\n",
    "    ai_output = \"\"\n",
    "    started_streaming = False\n",
    "    \n",
    "    for chunk in response:\n",
    "        if chunk.text:\n",
    "            content = chunk.text\n",
    "            ai_output += content\n",
    "            all_out +=content\n",
    "            if \"action: type:\" in ai_output and not started_streaming or \"action: type:\" in content:\n",
    "                started_streaming = True\n",
    "                action_type=True\n",
    "                ai_output = ai_output.split(\"action: type:\", 1)[1]\n",
    "                yield ai_output.encode()\n",
    "            elif started_streaming:\n",
    "                yield content.encode()\n",
    "        await asyncio.sleep(0.005)  # Add a small delay between chunks\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(\"http://localhost:8000/receive_stream\", data=get_ai_output()) as response:\n",
    "            result = await response.json()\n",
    "    \n",
    "\n",
    "time.sleep(5)  # Wait for 5 seconds before starting\n",
    "# Run the main function\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "80ab9b56-3613-44ab-a02d-df39c79931da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(all_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c24a80-7f3c-45ca-ad17-358c371e23b1",
   "metadata": {},
   "outputs": [],
   "source": [
    " youtube\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d33bf9b-f9a2-4698-88bd-1ad8680d847a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
