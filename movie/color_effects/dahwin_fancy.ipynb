{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86a5911-9c3c-40c5-8ae5-8e0f5e3f1d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from moviepy.editor import VideoFileClip\n",
    "from functools import partial\n",
    "\n",
    "# Step 1: Set the video filenames\n",
    "video_filenames = [\"fancy.mp4\", \"feel.mp4\", \"fancy.mp4\", \"feel.mp4\"]\n",
    "\n",
    "# Step 2: Create VideoFileClip objects from the videos\n",
    "video_clips1 = []\n",
    "for filename in video_filenames:\n",
    "    video = VideoFileClip(filename).subclip(0,3)\n",
    "    video = video.resize(height=1080)\n",
    "    video = video.set_position((\"center\", \"center\"))  # Set video position to center\n",
    "    video_clips1.append(video)\n",
    "\n",
    "\n",
    "color_list = ['BONE', 'OCEAN', 'quiet', 'DEEPGREEN', 'HOT', 'COOL', 'PINK',\n",
    "              'INFERNO', 'CIVIDIS', 'RAINBOW', 'TWILIGHT', 'TURBO', 'BGR2RGB']\n",
    "\n",
    "\n",
    "def color_clips_lists(video_clips,color_lists):\n",
    "    # Create a list to store the color-graded video clips\n",
    "    color_clips_list = []\n",
    "\n",
    "    # Define the apply_colormap function\n",
    "    def apply_colormap(frame, color):\n",
    "        # Convert the frame to grayscale and then to 8-bit depth\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray_frame_8bit = cv2.convertScaleAbs(gray_frame)\n",
    "\n",
    "        # Apply the specified colormap from color_list\n",
    "        colormap = getattr(cv2, f'COLORMAP_{color}')\n",
    "        colored_frame = cv2.applyColorMap(gray_frame_8bit, colormap)\n",
    "\n",
    "        return colored_frame\n",
    "\n",
    "    # Iterate through video clips and color list\n",
    "    for video_clip, color in zip(video_clips, color_lists):\n",
    "        if color.lower() == 'quiet':\n",
    "            def bgr_to_rgb(frame):\n",
    "                return frame[..., ::-1]  # Reverse BGR to RGB\n",
    "\n",
    "            # Apply bgr_to_rgb function if color is 'none'\n",
    "            color_clip = video_clip.fl_image(bgr_to_rgb)\n",
    "        else:\n",
    "            # Use functools.partial to create a partially applied function\n",
    "            apply_colormap_partial = partial(apply_colormap, color=color)\n",
    "            color_clip = video_clip.fl_image(apply_colormap_partial)\n",
    "\n",
    "        # Add the color-graded clip to the list\n",
    "        color_clips_list.append(color_clip)\n",
    "    return color_clips_list\n",
    "\n",
    "\n",
    "# Create color-graded video clips\n",
    "color_clips = color_clips_lists(video_clips1, color_list)\n",
    "\n",
    "# # Concatenate the color-graded video clips into one video\n",
    "# final_video = concatenate_videoclips(color_clips, method=\"compose\")\n",
    "\n",
    "# # Export the final video to \"color0.mp4\"\n",
    "# final_video.write_videofile(\"color0.mp4\", codec=\"libx264\", fps=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca15a9ef-d11d-43eb-b7cc-4c02b1457688",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from moviepy.editor import *\n",
    "video_clips = color_clips\n",
    "padding = 0.6\n",
    "video_fx_list = [video_clips[0]]\n",
    "\n",
    "idx = video_clips[0].duration - padding\n",
    "for video in video_clips[1:]:\n",
    "    video_fx_list.append(video.set_start(idx).crossfadein(padding))\n",
    "    idx += video.duration - padding\n",
    "\n",
    "final_video = CompositeVideoClip(video_fx_list)\n",
    "# Concatenate the color-graded video clips into one video\n",
    "final_video = concatenate_videoclips([final_video,video_clips1[1]], method=\"compose\")\n",
    "# Export the final video to \"color0.mp4\"\n",
    "# final_video.write_videofile(\"color0.mp4\", codec=\"libx264\", fps=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf2c2002-8ab1-40ca-b474-09a424fb33ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video written with cv2 successfully.\n"
     ]
    }
   ],
   "source": [
    "# Get the frames from the final_video\n",
    "frames = final_video.get_frame(0)  # Get the first frame to determine frame size\n",
    "frame_size = frames.shape[1], frames.shape[0]\n",
    "\n",
    "# Define the output video file path\n",
    "output_video_path = \"color1.mp4\"\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can change the codec as needed\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, 24.0, frame_size)\n",
    "\n",
    "# Iterate through the frames and write them to the output video\n",
    "for frame in final_video.iter_frames(fps=24):\n",
    "    out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# Release the VideoWriter and close the output file\n",
    "out.release()\n",
    "\n",
    "print(\"Video written with cv2 successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "112e7514-4f7f-4fc7-88ff-cfc66b54e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store frames and audio\n",
    "frames = []\n",
    "audio = []\n",
    "from tqdm import tqdm\n",
    "# Estimate the total number of frames\n",
    "total_frames = int(final_video.duration * final_video.fps)\n",
    "\n",
    "# Iterate through the frames and append each frame as a NumPy array\n",
    "for frame in tqdm(final_video.iter_frames(fps=final_video.fps, dtype='uint8'), total=total_frames):\n",
    "    frames.append(frame)\n",
    "    audio.append(final_video.audio.get_frame(final_video.duration * len(frames) / total_frames))\n",
    "\n",
    "# Convert the list of frames to a NumPy array\n",
    "combined_array = np.array(frames)\n",
    "\n",
    "# Get video dimensions\n",
    "height, width, _ = combined_array[0].shape\n",
    "\n",
    "# Create a VideoWriter object to save the video as an MP4 file\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4\n",
    "output_video = cv2.VideoWriter('dahyuncv2.mp4', fourcc, final_video.fps, (width, height))\n",
    "\n",
    "# Write each frame to the output video\n",
    "for frame in tqdm(combined_array, total=total_frames):\n",
    "    output_video.write(frame)\n",
    "\n",
    "# Release the output video\n",
    "output_video.release()\n",
    "\n",
    "# Combine the audio frames into a NumPy array\n",
    "audio_array = np.array(audio)\n",
    "\n",
    "# Save the audio as a WAV file with a constant sample rate (e.g., 44100 Hz)\n",
    "audio_file = \"combined_audio.wav\"\n",
    "final_video.audio.to_audiofile(audio_file, codec=\"pcm_s16le\", fps=44100)\n",
    "\n",
    "# Merge the video and audio\n",
    "merged_file = \"color2.mp4\"\n",
    "command = f\"ffmpeg -i dahyuncv2.mp4 -i {audio_file} -c:v copy -c:a aac -strict experimental -y {merged_file}\"\n",
    "os.system(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46976901-3d44-4fec-a467-15f676899671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from moviepy.editor import VideoClip\n",
    "from moviepy.video.io.ffmpeg_tools import np2vid\n",
    "\n",
    "# Assuming you already have combined_array as a NumPy array of frames\n",
    "\n",
    "# Define a custom function to generate frames\n",
    "def frame_generator(t):\n",
    "    frame_index = int(t * final_video.fps)\n",
    "    if frame_index < len(combined_array):\n",
    "        return combined_array[frame_index]\n",
    "    else:\n",
    "        return combined_array[-1]\n",
    "\n",
    "# Create a VideoClip using the custom frame generator\n",
    "video_clip = VideoClip(frame_generator, duration=final_video.duration)\n",
    "\n",
    "# Now you have a moviepy VideoClip named video_clip without audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4226363b-9c52-49f2-9939-26cbcf9f8e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80c7f39-a285-488b-b660-721b45c4725d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f013f27c-2c94-4f10-b497-de6045502340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608db017-2a2a-4df0-8706-de81a66bb5db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
