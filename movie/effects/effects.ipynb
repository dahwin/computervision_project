{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f25e2a16-f8fc-4bc2-b957-6ee47e9e0ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video 1transitionclip.mp4.\n",
      "MoviePy - Writing audio in 1transitionclipTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video 1transitionclip.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready 1transitionclip.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from moviepy.editor import *\n",
    "\n",
    "# Step 1: Set the video filenames\n",
    "video_filenames = ['motion.mp4',\"motion.mp4\"]\n",
    "\n",
    "# Step 2: Create VideoFileClip objects from the videos\n",
    "video_clips = []\n",
    "for filename in video_filenames:\n",
    "    video = VideoFileClip(filename).subclip(0,6)\n",
    "    video = video.resize(height=1080)\n",
    "    video = video.set_position((\"center\", \"center\"))  # Set video position to center\n",
    "    \n",
    "    video_clips.append(video)\n",
    "def crossfade(video0,video1):\n",
    "        # Step 3: Define transition duration\n",
    "    transition_duration = 1  # Duration of the slide-in transition in seconds\n",
    "\n",
    "    # Step 4: Extract the last one second of clip1 and the first one second of clip2\n",
    "    clip1_last_second = video0.subclip(-1, None)\n",
    "    clip2_first_second = video1.subclip(0, 1.2)\n",
    "    clips = [clip1_last_second,clip2_first_second]\n",
    "    padding = 0.6\n",
    "    video_fx_list = [clips[0]]\n",
    "    idx = clips[0].duration - padding\n",
    "\n",
    "    for video in clips[1:]:\n",
    "        video_fx_list.append(video.set_start(idx).crossfadein(padding))\n",
    "        idx += video.duration - padding\n",
    "\n",
    "    # final_width = max(clip.w for clip in clips)\n",
    "    # final_height = max(clip.h for clip in clips)\n",
    "    # final_video = CompositeVideoClip(video_fx_list, size=(final_width, final_height))\n",
    "    final_video = CompositeVideoClip(video_fx_list)\n",
    "    # final_video = concatenate_videoclips(video_fx_list,method='compose')\n",
    "\n",
    "    return final_video\n",
    "\n",
    "def slidein(video0, video1):\n",
    "    transition_duration = 1  # Duration of the slide-in transition in seconds\n",
    "\n",
    "    clip1_last_second = video0.subclip(-1, None)\n",
    "    clip2_first_second = video1.subclip(0, 1.3)\n",
    "\n",
    "    if clip1_last_second.aspect_ratio < 1.78:\n",
    "        width = int(1080 * clip1_last_second.aspect_ratio)\n",
    "        padding = (1920 - width) // 2\n",
    "        clip1_frames = [cv2.copyMakeBorder(frame, 0, 0, padding, padding, cv2.BORDER_CONSTANT, value=[0, 0, 0]) for\n",
    "                        frame in clip1_last_second.iter_frames()]\n",
    "    else:\n",
    "        clip1_frames = [frame for frame in clip1_last_second.iter_frames()]\n",
    "\n",
    "    if clip2_first_second.aspect_ratio < 1.78:\n",
    "        width = int(1080 * clip2_first_second.aspect_ratio)\n",
    "        padding = (1920 - width) // 2\n",
    "        clip2_frames = [cv2.copyMakeBorder(frame, 0, 0, padding, padding, cv2.BORDER_CONSTANT, value=[0, 0, 0]) for\n",
    "                        frame in clip2_first_second.iter_frames()]\n",
    "    else:\n",
    "        clip2_frames = [frame for frame in clip2_first_second.iter_frames()]\n",
    "\n",
    "    transition_frames = []\n",
    "    height, width, _ = clip1_frames[0].shape\n",
    "    num_frames = min(len(clip1_frames), len(clip2_frames), int(transition_duration * clip1_last_second.fps))\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        alpha = i / num_frames\n",
    "        tx_clip1 = -int((width / num_frames) * i)\n",
    "        tx_clip2 = width - int((width / num_frames) * i)\n",
    "        frame_clip1 = cv2.warpAffine(clip1_frames[i], np.float32([[1, 0, tx_clip1], [0, 1, 0]]), (width, height))\n",
    "\n",
    "        if i < len(clip2_frames):\n",
    "            frame_clip2 = cv2.warpAffine(clip2_frames[i], np.float32([[1, 0, tx_clip2], [0, 1, 0]]),\n",
    "                                         (width, height))\n",
    "        else:\n",
    "            frame_clip2 = cv2.warpAffine(clip2_frames[-1], np.float32([[1, 0, tx_clip2], [0, 1, 0]]),\n",
    "                                         (width, height))\n",
    "\n",
    "        blend_frame = cv2.addWeighted(frame_clip1, 1 - alpha, frame_clip2, alpha, 0)\n",
    "        transition_frames.append(blend_frame)\n",
    "\n",
    "    remaining_frames = clip2_frames[num_frames:]\n",
    "    transition_frames.extend(remaining_frames)\n",
    "\n",
    "    def get_transition_frame(t):\n",
    "        frame_index = int(t * clip1_last_second.fps)\n",
    "        if 0 <= frame_index < len(transition_frames):\n",
    "            return transition_frames[frame_index]\n",
    "        else:\n",
    "            return transition_frames[-1]  # Use the last frame if index is out of range\n",
    "\n",
    "    transition_clip = VideoClip(make_frame=get_transition_frame, duration=transition_duration)\n",
    "    # transition_clip = VideoClip(make_frame=lambda t: transition_frames[int(t * clip1_last_second.fps)],\n",
    "    #                             duration=transition_duration)\n",
    "\n",
    "    return transition_clip\n",
    "    \n",
    "# Use the convert_string_to_final_clip function to get the final_clip\n",
    "# final_clip_str = convert_string_to_final_clip(input_string1)\n",
    "video = video_clips[0]\n",
    "# Evaluate the final_clip_str to get the final_clip video clip object\n",
    "final_clip = concatenate_videoclips([video_clips[0].subclip(0, video_clips[0].duration - 1),slidein(video_clips[0],video_clips[1]), video_clips[1].subclip(1.3, video_clips[1].duration - 1)],method='compose')\n",
    "\n",
    "\n",
    "target_resolution = (1920, 1080)\n",
    "\n",
    "# Resize the combined clip to the target resolution\n",
    "final_clips = final_clip.resize(height=target_resolution[1], width=target_resolution[0])\n",
    "# Step 8: Write the final video to a file\n",
    "final_clips.write_videofile(\"1transitionclip.mp4\", codec=\"libx264\", fps=video.fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b8e2fd-d212-4d55-bc96-8ba5bef5945f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video something.mp4.\n",
      "MoviePy - Writing audio in somethingTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video something.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready something.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from moviepy.editor import *\n",
    "\n",
    "# Step 1: Set the video filenames\n",
    "video_filenames = ['motion.mp4', \"motion.mp4\"]\n",
    "\n",
    "# Step 2: Create VideoFileClip objects from the videos\n",
    "video_clips = []\n",
    "for filename in video_filenames:\n",
    "    video = VideoFileClip(filename).subclip(0, 6)\n",
    "    video = video.resize(height=1080)\n",
    "    video = video.set_position((\"center\", \"center\"))  # Set video position to center\n",
    "\n",
    "    video_clips.append(video)\n",
    "\n",
    "def something(video0, video1):\n",
    "    # Extract the last one second of video0 and the first 1.2 seconds of video1\n",
    "    clip1_last_second = video0.subclip(-1, None)\n",
    "    clip2_first_second = video1.subclip(0, 1.2)\n",
    "    # Simply concatenate the two video clips without any transition\n",
    "    final_video = concatenate_videoclips([clip1_last_second, clip2_first_second])\n",
    "    return final_video\n",
    "\n",
    "\n",
    "\n",
    "# Use the convert_string_to_final_clip function to get the final_clip\n",
    "# final_clip_str = convert_string_to_final_clip(input_string1)\n",
    "video = video_clips[0]\n",
    "# Evaluate the final_clip_str to get the final_clip video clip object\n",
    "final_clip = concatenate_videoclips([video_clips[0].subclip(0, video_clips[0].duration - 1),something(video_clips[0],video_clips[1]), video_clips[1].subclip(1.3, video_clips[1].duration - 1)],method='compose')\n",
    "\n",
    "\n",
    "target_resolution = (1920, 1080)\n",
    "\n",
    "# Resize the combined clip to the target resolution\n",
    "final_clips = final_clip.resize(height=target_resolution[1], width=target_resolution[0])\n",
    "# Step 8: Write the final video to a file\n",
    "final_clips.write_videofile(\"something.mp4\", codec=\"libx264\", fps=video.fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54eb8776-ffd7-43cd-a64b-adcf4b337e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect Ratio: 0.562962962962963\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Open the video file\n",
    "video_path = r\"something.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the width and height of the video\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Calculate the aspect ratio\n",
    "aspect_ratio = width / height\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Print the aspect ratio\n",
    "print(\"Aspect Ratio:\", aspect_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8038a49f-4340-4519-b6e7-5d9699e2d0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
