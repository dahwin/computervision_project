{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecd38819-6819-4e64-ac1c-d452d67bd975",
   "metadata": {},
   "source": [
    "# '''dahyun+darwin= dahwin'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44c8e90b-e3a1-449c-9c33-952c4a95f1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video black_test.mp4.\n",
      "Moviepy - Writing video black_test.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready black_test.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ColorClip, CompositeVideoClip\n",
    "\n",
    "# Define the width and height of the black background\n",
    "background_width = 1920\n",
    "background_height = 1080\n",
    "\n",
    "# Create a black color clip as the background\n",
    "background_clip = ColorClip((background_width, background_height), color=(0, 0, 0)).set_duration(6)\n",
    "\n",
    "# Set the target resolution to HD (1920x1080)\n",
    "target_resolution = (1920, 1080)\n",
    "\n",
    "# Resize the background clip to the target resolution\n",
    "background_clip = background_clip.resize(height=target_resolution[1], width=target_resolution[0])\n",
    "\n",
    "# Composite the background clip\n",
    "final_clip = CompositeVideoClip([background_clip])\n",
    "\n",
    "# Write the final clip to a new file\n",
    "final_clip.write_videofile(\"black_test.mp4\", fps=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee665abb-31ab-4b8e-8f26-447bdfb401ac",
   "metadata": {},
   "source": [
    "# I need to image fit according aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11fab841-fa5f-40e1-8d1a-b6f3bf29fedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test.mp4.\n",
      "Moviepy - Writing video test.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageClip, concatenate_videoclips\n",
    "\n",
    "# Step 1: Set the image filenames\n",
    "image_filenames = [\"nn.jpg\", \"n.jpeg\",'m.jpeg']\n",
    "\n",
    "# Step 2: Set the duration for each image (in seconds)\n",
    "image_durations = [5, 5,5]  # Adjust the durations as needed\n",
    "\n",
    "# Step 3: Create ImageClip objects from the images\n",
    "image_clips = []\n",
    "for filename, duration in zip(image_filenames, image_durations):\n",
    "    image = ImageClip(filename, duration=duration)\n",
    "    # Resize image to fit within the video dimensions while maintaining aspect ratio\n",
    "    image = image.resize(height=1080)\n",
    "    image = image.set_position((\"center\", \"center\"))  # Set image position to center\n",
    "    image_clips.append(image)\n",
    "\n",
    "# Step 4: Concatenate the image clips into a single video clip\n",
    "video_clip = concatenate_videoclips(image_clips, method=\"compose\")\n",
    "\n",
    "# Step 5: Set the output video filename\n",
    "output_filename = \"test.mp4\"\n",
    "\n",
    "# Step 6: Write the video file\n",
    "video_clip.write_videofile(output_filename, fps=10, codec=\"libx264\",\n",
    "                           audio_codec=\"aac\", bitrate=\"5000k\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3a2c261-2659-4f12-b079-a82946036002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageSequenceClip, concatenate_videoclips\n",
    "\n",
    "# List of image filenames in the desired order\n",
    "image_files = [\"nn.jpg\", \"n.jpeg\", \"m.jpeg\"]\n",
    "\n",
    "# Create a list of ImageClips from the image files\n",
    "image_clips = []\n",
    "for filename in image_files:\n",
    "    # Load the image clip from the file\n",
    "    image_clip = ImageSequenceClip([filename],fps=24)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1c5b1c8-035e-4164-83b1-430a91844cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  14%|█████████▉                                                           | 13/90 [00:18<00:26,  2.94it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video imagetovideo.mp4.\n",
      "Moviepy - Writing video imagetovideo.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "t:   0%|                                                                              | 0/30 [00:00<?, ?it/s, now=None]\u001b[A\n",
      "t:  10%|███████                                                               | 3/30 [00:01<00:15,  1.69it/s, now=None]\u001b[A\n",
      "t:  17%|███████████▋                                                          | 5/30 [00:01<00:08,  3.01it/s, now=None]\u001b[A\n",
      "t:  23%|████████████████▎                                                     | 7/30 [00:02<00:05,  4.51it/s, now=None]\u001b[A\n",
      "t:  30%|█████████████████████                                                 | 9/30 [00:02<00:03,  6.06it/s, now=None]\u001b[A\n",
      "t:  37%|█████████████████████████▎                                           | 11/30 [00:02<00:02,  7.48it/s, now=None]\u001b[A\n",
      "t:  43%|█████████████████████████████▉                                       | 13/30 [00:02<00:02,  7.68it/s, now=None]\u001b[A\n",
      "t:  50%|██████████████████████████████████▌                                  | 15/30 [00:02<00:01,  7.71it/s, now=None]\u001b[A\n",
      "t:  57%|███████████████████████████████████████                              | 17/30 [00:03<00:01,  8.13it/s, now=None]\u001b[A\n",
      "t:  63%|███████████████████████████████████████████▋                         | 19/30 [00:03<00:01,  8.44it/s, now=None]\u001b[A\n",
      "t:  67%|██████████████████████████████████████████████                       | 20/30 [00:03<00:01,  8.50it/s, now=None]\u001b[A\n",
      "t:  70%|████████████████████████████████████████████████▎                    | 21/30 [00:03<00:01,  8.24it/s, now=None]\u001b[A\n",
      "t:  73%|██████████████████████████████████████████████████▌                  | 22/30 [00:03<00:01,  7.98it/s, now=None]\u001b[A\n",
      "t:  77%|████████████████████████████████████████████████████▉                | 23/30 [00:03<00:00,  7.80it/s, now=None]\u001b[A\n",
      "t:  80%|███████████████████████████████████████████████████████▏             | 24/30 [00:03<00:00,  8.07it/s, now=None]\u001b[A\n",
      "t:  83%|█████████████████████████████████████████████████████████▌           | 25/30 [00:03<00:00,  8.28it/s, now=None]\u001b[A\n",
      "t:  87%|███████████████████████████████████████████████████████████▊         | 26/30 [00:04<00:00,  8.34it/s, now=None]\u001b[A\n",
      "t:  90%|██████████████████████████████████████████████████████████████       | 27/30 [00:04<00:00,  8.44it/s, now=None]\u001b[A\n",
      "t:  93%|████████████████████████████████████████████████████████████████▍    | 28/30 [00:04<00:00,  8.60it/s, now=None]\u001b[A\n",
      "t:  97%|██████████████████████████████████████████████████████████████████▋  | 29/30 [00:04<00:00,  8.17it/s, now=None]\u001b[A\n",
      "t: 100%|█████████████████████████████████████████████████████████████████████| 30/30 [00:04<00:00,  7.82it/s, now=None]\u001b[A\n",
      "t:  14%|█████████▉                                                           | 13/90 [00:23<00:26,  2.94it/s, now=None]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready imagetovideo.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageSequenceClip, concatenate_videoclips\n",
    "\n",
    "# List of image filenames in the desired order\n",
    "image_files = [\"nn.jpg\", \"n.jpeg\", \"m.jpeg\"]\n",
    "\n",
    "# Create a list of ImageClips from the image files\n",
    "image_clips = []\n",
    "for filename in image_files:\n",
    "    # Load the image clip from the file\n",
    "    image_clip = ImageSequenceClip([filename],fps=1)\n",
    "\n",
    "    # Resize the image clip to height=1080\n",
    "    image_clip = image_clip.resize(height=1080)\n",
    "\n",
    "    # Set the position of the image clip to (\"center\", \"center\")\n",
    "    image_clip = image_clip.set_position((\"center\", \"center\"))\n",
    "\n",
    "    # Append the modified image clip to the list\n",
    "    image_clips.append(image_clip)\n",
    "clip = VideoFileClip(\"motion.mp4\").subclip(0,6)\n",
    "# Concatenate the image clips to create the final video clip\n",
    "video_clip = concatenate_videoclips(image_clips, method=\"compose\")\n",
    "# video_clip = concatenate_videoclips([video_clip,clip],method='compose')\n",
    "# Set the target resolution to HD (1920x1080)\n",
    "target_resolution = (1920, 1080)\n",
    "\n",
    "# Resize the combined clip to the target resolution\n",
    "video_clip = video_clip.resize(height=target_resolution[1], width=target_resolution[0])\n",
    "\n",
    "# Set the output video file name and extension\n",
    "output_filename = \"imagetovideo.mp4\"\n",
    "\n",
    "# Write the video clip to the output file\n",
    "video_clip.write_videofile(output_filename, fps=10, codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a240bb8-0796-433a-9e3b-f977d7058fce",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa5ec609-74d6-427c-89b6-04391cbba477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video videoex.mp4.\n",
      "MoviePy - Writing audio in videoexTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video videoex.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready videoex.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "\n",
    "# Step 1: Set the video filenames\n",
    "video_filenames = [\"fancy.mp4\", \"motion.mp4\"]\n",
    "\n",
    "# Step 2: Create VideoFileClip objects from the videos\n",
    "video_clips = []\n",
    "for filename in video_filenames:\n",
    "    video = VideoFileClip(filename)\n",
    "    video = video.resize(height=1080)\n",
    "    video = video.set_position((\"center\", \"center\"))  # Set video position to center\n",
    "    video_clips.append(video)\n",
    "\n",
    "# Step 3: Concatenate the video clips into a single video clip\n",
    "final_clip = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "\n",
    "# Step 4: Set the output video filename\n",
    "output_filename = \"videoex.mp4\"\n",
    "\n",
    "# Step 5: Write the video file\n",
    "final_clip.write_videofile(output_filename, codec=\"libx264\", audio_codec=\"aac\", bitrate=\"5000k\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f757f2-633d-4101-811a-3119e64ea242",
   "metadata": {},
   "source": [
    "# Portrait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b38099-16a3-4b39-81c1-8681e5f84ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, concatenate_videoclips,vfx , AudioFileClip\n",
    "from moviepy import editor\n",
    "from moviepy.editor import transfx\n",
    "\n",
    "clip1 = VideoFileClip('fancy.mp4').subclip(0,6).fx(vfx.fadein,1).fx(vfx.fadeout,1)\n",
    "clip2 = VideoFileClip('motion.mp4').subclip(0,6).fx(vfx.fadein,1).fx(vfx.fadeout,1)\n",
    "\n",
    "combined = concatenate_videoclips([clip1,clip2],method=\"compose\")\n",
    "combined.write_videofile('videoexx.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aad677-49fd-4319-93d9-0698c749224e",
   "metadata": {},
   "source": [
    "# youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8cf6915-927f-4d59-b01b-01113e96a642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video videoexx.mp4.\n",
      "MoviePy - Writing audio in videoexxTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video videoexx.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready videoexx.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, concatenate_videoclips, vfx\n",
    "\n",
    "# Load video clips and apply fade effects\n",
    "clip1 = VideoFileClip('fancy.mp4').subclip(0, 6).fx(vfx.fadein, 1).fx(vfx.fadeout, 1)\n",
    "clip2 = VideoFileClip('motion.mp4').subclip(0, 6).fx(vfx.fadein, 1).fx(vfx.fadeout, 1)\n",
    "\n",
    "# Resize and set_position for each clip\n",
    "clip1 = clip1.resize(height=1080)\n",
    "clip1 = clip1.set_position((\"center\", \"center\"))\n",
    "\n",
    "clip2 = clip2.resize(height=1080)\n",
    "clip2 = clip2.set_position((\"center\", \"center\"))\n",
    "\n",
    "# Concatenate the clips\n",
    "combined = concatenate_videoclips([clip1, clip2], method=\"compose\")\n",
    "combined.write_videofile('videoexx.mp4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6980be-4a2e-4e43-bfdb-3f6be3a68eb7",
   "metadata": {},
   "source": [
    "# cross fade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7d9b05b-a556-4e8e-99d5-dcda76f6a7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video differentcross.mp4.\n",
      "MoviePy - Writing audio in differentcrossTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video differentcross.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready differentcross.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "\n",
    "def create_crossfade_video(clips):\n",
    "    padding = 0.6\n",
    "    video_fx_list = [clips[0]]\n",
    "    idx = clips[0].duration - padding\n",
    "\n",
    "    for video in clips[1:]:\n",
    "        video_fx_list.append(video.set_start(idx).crossfadein(padding))\n",
    "        idx += video.duration - padding\n",
    "\n",
    "    # final_width = max(clip.w for clip in clips)\n",
    "    # final_height = max(clip.h for clip in clips)\n",
    "    # final_video = CompositeVideoClip(video_fx_list, size=(final_width, final_height))\n",
    "    final_video = CompositeVideoClip(video_fx_list)\n",
    "    # final_video = concatenate_videoclips(video_fx_list,method='compose')\n",
    "\n",
    "    return final_video\n",
    "\n",
    "# Step 1: Set the video filenames\n",
    "video_filenames = [\"fancy.mp4\", \"motion.mp4\"]\n",
    "\n",
    "# Step 2: Create VideoFileClip objects from the videos\n",
    "video_clips = []\n",
    "for filename in video_filenames:\n",
    "    video = VideoFileClip(filename)\n",
    "    video = video.resize(height=1080)\n",
    "    video = video.set_position((\"center\", \"center\"))  # Set video position to center\n",
    "    video_clips.append(video)\n",
    "    \n",
    "final = create_crossfade_video(video_clips)\n",
    "\n",
    "final.write_videofile('differentcross.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832fabbb-6fb5-4fb9-a273-c3b175dcfea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video differentcross.mp4.\n",
      "MoviePy - Writing audio in differentcrossTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video differentcross.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready differentcross.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "\n",
    "def create_crossfade_video(clips):\n",
    "    padding = 0.5\n",
    "    video_fx_list = [clips[0]]\n",
    "    idx = clips[0].duration - padding\n",
    "\n",
    "    for video in clips[1:]:\n",
    "        video_fx_list.append(video.set_start(idx).crossfadein(padding))\n",
    "        idx += video.duration - padding\n",
    "\n",
    "    final_video = CompositeVideoClip(video_fx_list)\n",
    "\n",
    "    return final_video\n",
    "\n",
    "# Step 1: Set the video filenames\n",
    "video_filenames = [\"tofu.mp4\", \"dance.mp4\"]\n",
    "\n",
    "# Step 2: Create VideoFileClip objects from the videos\n",
    "video_clips = []\n",
    "for filename in video_filenames:\n",
    "    video = VideoFileClip(filename).subclip(0,2.5)\n",
    "    video = video.resize(height=1080)\n",
    "    video = video.set_position((\"center\", \"center\"))  # Set video position to center\n",
    "    video_clips.append(video)\n",
    "    \n",
    "final = create_crossfade_video(video_clips)\n",
    "\n",
    "final.write_videofile('differentcross.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a973211d-2d6a-400d-9fd3-e2590d97202e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'VideoFileClip' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 54\u001b[0m\n\u001b[0;32m     52\u001b[0m video \u001b[38;5;241m=\u001b[39m video_clips[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Evaluate the final_clip_str to get the final_clip video clip object\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m final_clip \u001b[38;5;241m=\u001b[39m concatenate_videoclips([video_clips[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msubclip(\u001b[38;5;241m0\u001b[39m, video_clips[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mduration \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m),\u001b[43mcrossfade\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_clips\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvideo_clips\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, video_clips[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msubclip(\u001b[38;5;241m1.3\u001b[39m, video_clips[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mduration \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)],method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompose\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     57\u001b[0m target_resolution \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1920\u001b[39m, \u001b[38;5;241m1080\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Resize the combined clip to the target resolution\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 42\u001b[0m, in \u001b[0;36mcrossfade\u001b[1;34m(video0, video1)\u001b[0m\n\u001b[0;32m     39\u001b[0m     crossfade_frames\u001b[38;5;241m.\u001b[39mappend(blend_frame)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Calculate the remaining frames count based on the time duration\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m remaining_frames_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(clip2_first_second\u001b[38;5;241m.\u001b[39mfps \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclip2_first_second\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m num_frames))\n\u001b[0;32m     43\u001b[0m remaining_frames \u001b[38;5;241m=\u001b[39m [clip2_first_second\u001b[38;5;241m.\u001b[39mget_frame(t \u001b[38;5;241m/\u001b[39m clip2_first_second\u001b[38;5;241m.\u001b[39mfps) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(remaining_frames_count)]\n\u001b[0;32m     44\u001b[0m crossfade_frames\u001b[38;5;241m.\u001b[39mextend(remaining_frames)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'VideoFileClip' has no len()"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from moviepy.editor import *\n",
    "\n",
    "# Step 1: Set the video filenames\n",
    "video_filenames = ['motion.mp4',\"motion.mp4\"]\n",
    "\n",
    "# Step 2: Create VideoFileClip objects from the videos\n",
    "video_clips = []\n",
    "for filename in video_filenames:\n",
    "    video = VideoFileClip(filename).subclip(0,6)\n",
    "    video = video.resize(height=1080)\n",
    "    video = video.set_position((\"center\", \"center\"))  # Set video position to center\n",
    "    \n",
    "    video_clips.append(video)\n",
    "def crossfade(video0, video1):\n",
    "        # Step 3: Define transition duration\n",
    "    transition_duration = 1  # Duration of the slide-in transition in seconds\n",
    "    \n",
    "    # Step 4: Extract the last one second of clip1 and the first one second of clip2\n",
    "    clip1_last_second = video0.subclip(-1, None)\n",
    "    clip2_first_second = video1.subclip(0, 1.3)\n",
    "    \n",
    "    # Check if aspect ratio of clip1_last_second is less than 1.78:1 and add black padding\n",
    "    if clip1_last_second.aspect_ratio < 1.78:\n",
    "        width = int(1080 * clip1_last_second.aspect_ratio)\n",
    "        padding = (1920 - width) // 2\n",
    "        clip1_frames = [cv2.copyMakeBorder(frame, 0, 0, padding, padding, cv2.BORDER_CONSTANT, value=[0, 0, 0]) for frame in clip1_last_second.iter_frames()]\n",
    "        # clip1_frames = [frame for frame in clip1_last_second.iter_frames()]\n",
    "    else:\n",
    "        clip1_frames = [frame for frame in clip1_last_second.iter_frames()]\n",
    "    \n",
    "    # Check if aspect ratio of clip2_first_second is less than 1.78:1 and add black padding\n",
    "    if clip2_first_second.aspect_ratio < 1.78:\n",
    "        width = int(1080 * clip2_first_second.aspect_ratio)\n",
    "        padding = (1920 - width) // 2\n",
    "        clip2_frames = [cv2.copyMakeBorder(frame, 0, 0, padding, padding, cv2.BORDER_CONSTANT, value=[0, 0, 0]) for frame in clip2_first_second.iter_frames()]\n",
    "        # clip2_frames = [frame for frame in clip2_first_second.iter_frames()]\n",
    "    else:\n",
    "        \n",
    "        clip2_frames = [frame for frame in clip2_first_second.iter_frames()]\n",
    "    \n",
    "    # Step 6: Perform slide-in transition using numpy and cv2\n",
    "    transition_frames = []\n",
    "    height, width, _ = clip1_frames[0].shape\n",
    "    \n",
    "    # Ensure the number of frames matches the expected duration\n",
    "    num_frames = min(len(clip1_frames), len(clip2_frames), int(transition_duration * clip1_last_second.fps))\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        alpha = i / num_frames  # Linearly increasing alpha value\n",
    "    \n",
    "        # Calculate the translation distance based on the frame index\n",
    "        tx_clip1 = -int((width / num_frames) * i)\n",
    "        tx_clip2 = width - int((width / num_frames) * i)\n",
    "    \n",
    "        # Apply translation to clip1\n",
    "        frame_clip1 = cv2.warpAffine(clip1_frames[i], np.float32([[1, 0, tx_clip1], [0, 1, 0]]), (width, height))\n",
    "    \n",
    "        # Handle the case where clip2_frames has fewer frames than expected\n",
    "        if i < len(clip2_frames):\n",
    "            # Apply translation to clip2\n",
    "            frame_clip2 = cv2.warpAffine(clip2_frames[i], np.float32([[1, 0, tx_clip2], [0, 1, 0]]), (width, height))\n",
    "        else:\n",
    "            # Use the last frame of clip2_frames for the remaining frames\n",
    "            frame_clip2 = cv2.warpAffine(clip2_frames[-1], np.float32([[1, 0, tx_clip2], [0, 1, 0]]), (width, height))\n",
    "    \n",
    "        # Blend the frames to create the transition effect\n",
    "        blend_frame = cv2.addWeighted(frame_clip1, 1 - alpha, frame_clip2, alpha, 0)\n",
    "    \n",
    "        transition_frames.append(blend_frame)\n",
    "    \n",
    "    # Add remaining frames where clip2_first_second fills the entire screen\n",
    "    remaining_frames = clip2_frames[num_frames:]\n",
    "    transition_frames.extend(remaining_frames)\n",
    "    \n",
    "    \n",
    "    # Step 7: Create the transition clip using NumPy\n",
    "    transition_clip = VideoClip(make_frame=lambda t: transition_frames[int(t * clip1_last_second.fps)], duration=transition_duration)\n",
    "\n",
    "    return transition_clip\n",
    "# Use the convert_string_to_final_clip function to get the final_clip\n",
    "# final_clip_str = convert_string_to_final_clip(input_string1)\n",
    "video = video_clips[0]\n",
    "# Evaluate the final_clip_str to get the final_clip video clip object\n",
    "final_clip = concatenate_videoclips([video_clips[0].subclip(0, video_clips[0].duration - 1),crossfade(video_clips[0],video_clips[1]), video_clips[1].subclip(1.3, video_clips[1].duration - 1)],method='compose')\n",
    "\n",
    "\n",
    "target_resolution = (1920, 1080)\n",
    "\n",
    "# Resize the combined clip to the target resolution\n",
    "final_clips = final_clip.resize(height=target_resolution[1], width=target_resolution[0])\n",
    "# Step 8: Write the final video to a file\n",
    "final_clips.write_videofile(\"crossfade.mp4\", codec=\"libx264\", fps=video.fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed7168a-7911-4ca5-9834-8a388aeebcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageClip, concatenate_videoclips\n",
    "import cv2\n",
    "# Step 1: Set the image filenames\n",
    "image_filenames = [\"nn.jpg\", \"n.jpeg\",'m.jpeg']\n",
    "\n",
    "\n",
    "d = 5\n",
    "clip1 = ImageClip('nn.jpg',duration=d).resize(height=1080).set_position(('center','center'))\n",
    "clip2 = ImageClip('n.jpeg',duration=d).resize(height=1080).set_position(('center','center'))\n",
    "clip3 = ImageClip('m.jpeg',duration=d).resize(height=1080).set_position(('center','center'))\n",
    "# Step 3: Create ImageClip objects from the images\n",
    "image_clips = [clip1,clip2,clip3]\n",
    "\n",
    "\n",
    "# Step 4: Concatenate the image clips into a single video clip\n",
    "video_clip = concatenate_videoclips(image_clips, method=\"compose\")\n",
    "\n",
    "# Step 5: Set the output video filename\n",
    "# output_filename = \"other.mp4\"\n",
    "\n",
    "# # Step 6: Write the video file\n",
    "# video_clip.write_videofile(output_filename, fps=10, codec=\"libx264\",\n",
    "#                            audio_codec=\"aac\", bitrate=\"5000k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "454ac336-3a07-49c5-a2cc-d09672545162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from moviepy.editor import ImageClip, concatenate_videoclips\n",
    "\n",
    "# Step 1: Set the image filenames\n",
    "image_filenames = [\"nn.jpg\", \"n.jpeg\", \"m.jpeg\"]\n",
    "\n",
    "d = 5\n",
    "\n",
    "# Create ImageClip objects from the images\n",
    "image_clips = []\n",
    "for filename in image_filenames:\n",
    "    image_clip = ImageClip(filename, duration=d).resize(height=1080).set_position(('center', 'center'))\n",
    "    image_clips.append(image_clip)\n",
    "\n",
    "# Concatenate the image clips into a single video clip\n",
    "video_clip = concatenate_videoclips(image_clips, method=\"compose\")\n",
    "\n",
    "# Set the output video filename\n",
    "output_filename = \"cv2images.mp4\"\n",
    "\n",
    "# Define the video codec for OpenCV\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# Get the dimensions of the video clip\n",
    "width, height = video_clip.size\n",
    "\n",
    "# Set the desired frame rate (modify this as needed)\n",
    "fps = 30\n",
    "\n",
    "# Create a VideoWriter object\n",
    "video_writer = cv2.VideoWriter(output_filename, fourcc, fps, (width, height))\n",
    "\n",
    "# Iterate over the frames of the video clip\n",
    "for t in range(int(video_clip.duration * fps)):\n",
    "    # Get the frame at the given time\n",
    "    frame = video_clip.get_frame(t / fps)\n",
    "\n",
    "    # Convert the frame from RGB to BGR\n",
    "    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Write the frame to the video file\n",
    "    video_writer.write(frame_bgr)\n",
    "\n",
    "# Release the VideoWriter\n",
    "video_writer.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0c4b197-a5a6-4e88-8d8c-c3dd429931c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 5s\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import cv2\n",
    "from moviepy.editor import ImageClip, concatenate_videoclips, VideoFileClip,CompositeVideoClip\n",
    "\n",
    "# Step 1: Set the image filenames\n",
    "image_filenames = [\"nn.jpg\", \"n.jpeg\", \"m.jpeg\"]\n",
    "\n",
    "d = 5\n",
    "\n",
    "# Create ImageClip objects from the images\n",
    "image_clips = []\n",
    "for filename in image_filenames:\n",
    "    image_clip = ImageClip(filename, duration=d).resize(height=1080).set_position(('center', 'center'))\n",
    "    image_clips.append(image_clip)\n",
    "\n",
    "# Concatenate the image clips into a single video clip\n",
    "image_video_clip = concatenate_videoclips(image_clips, method=\"compose\")\n",
    "\n",
    "# Load the \"fancy.mp4\" video clip\n",
    "fancy_video_clip = VideoFileClip(\"fancy.mp4\",target_resolution=(1080, 1920))\n",
    "\n",
    "# Concatenate the image video clip and the fancy video clip\n",
    "final_clip = concatenate_videoclips([image_video_clip, fancy_video_clip],method='compose')\n",
    "\n",
    "# Set the output video filename\n",
    "output_filename = \"cv2imagesfancy.mp4\"\n",
    "\n",
    "# Define the video codec for OpenCV\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# Get the dimensions of the final clip\n",
    "width, height = final_clip.size\n",
    "\n",
    "# Set the desired frame rate (modify this as needed)\n",
    "fps = 30\n",
    "\n",
    "# Create a VideoWriter object\n",
    "video_writer = cv2.VideoWriter(output_filename, fourcc, fps, (width, height))\n",
    "\n",
    "# Iterate over the frames of the final clip\n",
    "for t in range(int(final_clip.duration * fps)):\n",
    "    # Get the frame at the given time\n",
    "    frame = final_clip.get_frame(t / fps)\n",
    "\n",
    "    # Convert the frame from RGB to BGR\n",
    "    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Write the frame to the video file\n",
    "    video_writer.write(frame_bgr)\n",
    "\n",
    "# Release the VideoWriter\n",
    "video_writer.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25d7cbc4-9509-44bd-bc64-458ae5a43db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dahyun\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('dahyun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a927d9d2-09ea-41b9-9a2c-422aaeda0490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The duration of C:\\Users\\ALL USER\\Desktop\\computervision_project\\movie\\onlytransition.mp4 is 1.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "\n",
    "# Load the video\n",
    "video_path = r\"C:\\Users\\ALL USER\\Desktop\\computervision_project\\movie\\onlytransition.mp4\"\n",
    "video = VideoFileClip(video_path)\n",
    "\n",
    "# Get the duration in seconds\n",
    "duration_seconds = video.duration\n",
    "\n",
    "print(f\"The duration of {video_path} is {duration_seconds:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c39926-7766-4de8-9686-e2a2bd279212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Duration (ms): 9720.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Specify the path to your video file\n",
    "video_path = \"1transitionclip.mp4\"\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the frames per second (fps) and total frame count\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Calculate the duration in milliseconds\n",
    "duration_ms = (frame_count / fps) * 1000\n",
    "\n",
    "# Print the duration in milliseconds\n",
    "print(\"Video Duration (ms):\", duration_ms)\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276e14a3-2ac7-4e2b-bcef-0821950cb1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video Duration (ms): 10320.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "431934f3-e195-45fa-8e80-c9be1c474214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2280.0\n"
     ]
    }
   ],
   "source": [
    "v = 12000\n",
    "r =v- duration_ms\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9e0bca2-e33d-4115-bf62-0a8980200530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1680\n"
     ]
    }
   ],
   "source": [
    "v = 12000\n",
    "r =v- 10320\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6c275a-12dc-4576-9141-16b981779343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
